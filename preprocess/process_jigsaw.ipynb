{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fac653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_TRAIN = DATA_DIR / \"jigsaw_dataset.csv\"\n",
    "OUT_FILE = DATA_DIR / \"jigsaw_gbv.csv\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a45c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from: /Users/macbook/Desktop/CLEAN_PROJECT/data/jigsaw-unintended-bias-in-toxicity-classification/train.csv\n",
      "Original shape: (1804874, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/t4jgtv1959v08mv587bzsrgc0000gn/T/ipykernel_95183/366144520.py:46: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask_nouns = df[\"comment_text\"].str.contains(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering women-related comments: (86719, 45)\n",
      "Final dataset shape (text, label): (86719, 2)\n",
      "Label counts:\n",
      " label\n",
      "0    76380\n",
      "1    10339\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved processed dataset to: /Users/macbook/Desktop/CLEAN_PROJECT/data/jigsaw_gbv.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare Jigsaw Unintended Bias dataset for HEARTS replication.\n",
    "\n",
    "Goal:\n",
    "- Build a dataset focused on comments about women/girls.\n",
    "- Create a binary label for gender-based harmful / misogynistic content.\n",
    "- Save a compact CSV: (comment_text, label).\n",
    "\n",
    "label = 1: GBV-related towards women\n",
    "label = 0: non-harmful / neutral comments about women\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading raw data from: {RAW_TRAIN}\")\n",
    "    df = pd.read_csv(RAW_TRAIN)\n",
    "    print(\"Original shape:\", df.shape)\n",
    "\n",
    "    # Ensure comment_text is string\n",
    "    df[\"comment_text\"] = df[\"comment_text\"].fillna(\"\").astype(str)\n",
    "\n",
    "    # 1. FILTER: COMMENTS ABOUT WOMEN / GIRLS\n",
    "\n",
    "    # A) Identity-based filter (Jigsaw identity column)\n",
    "    #    'female' is a float in [0,1]; >= 0.5 means strong association\n",
    "    female_col = \"female\"\n",
    "    if female_col not in df.columns:\n",
    "        df[female_col] = 0.0\n",
    "    mask_identity_strong = df[female_col] >= 0.5\n",
    "\n",
    "    # B) Strong noun-based keywords: explicit references to women/girls\n",
    "    female_nouns = [\n",
    "        \"woman\", \"women\", \"girl\", \"girls\",\n",
    "        \"lady\", \"ladies\",\n",
    "        \"mother\", \"mom\", \"mum\",\n",
    "        \"wife\", \"girlfriend\",\n",
    "        \"sister\", \"daughter\",\n",
    "        \"female\",\n",
    "    ]\n",
    "\n",
    "    noun_pattern = r\"\\b(\" + \"|\".join(re.escape(k) for k in female_nouns) + r\")\\b\"\n",
    "    mask_nouns = df[\"comment_text\"].str.contains(\n",
    "        noun_pattern, case=False, regex=True, na=False\n",
    "    )\n",
    "\n",
    "    # Final \"about women\" mask:\n",
    "    # strongly female-identified OR explicit female nouns\n",
    "    mask_female_related = mask_identity_strong | mask_nouns\n",
    "\n",
    "    df = df[mask_female_related].copy()\n",
    "    print(\"After filtering women-related comments:\", df.shape)\n",
    "\n",
    "    # 2. LABEL: HARMFUL / MISOGYNISTIC CONTENT TOWARDS WOMEN\n",
    "\n",
    "    # Base toxicity score (Jigsaw 'target' column)\n",
    "    if \"target\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'target' column not found in Jigsaw data.\")\n",
    "    toxic = df[\"target\"] >= 0.5  # you can tune this threshold\n",
    "\n",
    "    # Harm components ‚Äì GBV-like harmful signals\n",
    "    harm_cols = [\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"threat\",\n",
    "        \"severe_toxicity\",\n",
    "        \"sexual_explicit\",\n",
    "    ]\n",
    "\n",
    "    for col in harm_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    harm_component = (\n",
    "        (df[\"identity_attack\"] >= 0.3) |\n",
    "        (df[\"insult\"]          >= 0.3) |\n",
    "        (df[\"threat\"]          >= 0.3) |\n",
    "        (df[\"severe_toxicity\"] >= 0.3) |\n",
    "        (df[\"sexual_explicit\"] >= 0.3)\n",
    "    )\n",
    "\n",
    "    # Final binary label:\n",
    "    # 1 = toxic AND has at least one strong harm component\n",
    "    # 0 = still about women, but non-harmful / mild / neutral\n",
    "    df[\"label\"] = (toxic & harm_component).astype(int)\n",
    "\n",
    "    # 3. KEEP ONLY NEEDED COLUMNS\n",
    "\n",
    "    out = df[[\"comment_text\", \"label\"]].dropna()\n",
    "    print(\"Final dataset shape (text, label):\", out.shape)\n",
    "    print(\"Label counts:\\n\", out[\"label\"].value_counts())\n",
    "\n",
    "    # 4. SAVE\n",
    "\n",
    "    OUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out.to_csv(OUT_FILE, index=False)\n",
    "    print(f\"\\nSaved processed dataset to: {OUT_FILE.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2db6002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: /Users/macbook/Desktop/CLEAN_PROJECT/data/jigsaw_gbv.csv\n",
      "\n",
      "=== Sample: Harmful comments about women (label=1) ===\n",
      "----\n",
      "He's a goof, just like pretty boy/girl.\n",
      "----\n",
      "Being a woman is not female enough for feminists .\n",
      "----\n",
      "i bet that this loony tunes woman spends more on hats than the people she represents make in a year!!\n",
      "----\n",
      "Only someone wound way too tight and way too far into the trough for Trudeau would have taken my attempt at droll humour seriously.\n",
      "\n",
      "Of course there is no evidence Junior was complicit in this stupid, drunken escapade.\n",
      "\n",
      "Myself, I'm sorry the kid didn't get away with material on NDP political strategy and tactics.  Had he done so, maybe the Liberals would become as messed up campaign wise as the Dippers were in 2015.\n",
      "\n",
      "For the record, Nixon wasn`t complicit in the Watergate break in either.  A guy (Howard Hunt) four levels down with too big a budget, too much idle time and too little to do hatched this stupid  plot.  John Mitchell who reported to Nixon and was responsible for campaign planning and intelligence was too distracted and busy trying to keep his crazy, alcoholic wife Martha under control and he, too, was not aware of the break in.\n",
      "\n",
      "Nixon was guilty of complicity in trying to cover up the break in after the perpetrators were caught.\n",
      "\n",
      "RMN paid the price - and so did the country!\n",
      "----\n",
      "You know the old saying: garbage in, garbage out.\n",
      "\"Calgary‚Äôs unfounded rate was 10 per cent. ‚ÄúOur rate was lower than the average,‚Äù [Staff Sergeant] said, ‚Äúso our members do do good work ‚Äì but we can always do better.‚Äù\n",
      "\n",
      "An insult to police: \"do better\" based on what standard?  An insult to the public: the \"unfounded rate\", unfortunately, is meaningless.  Because we don't know what \"unfounded\" means.  Police departments have different interpretations.  To feminists, \"unfounded\" means police don't believe complainants (often called \"victims\", even before sexual assault is proven.) Not necessarily true.  Therefore, the \"unfounded rate\" is...garbage.  Garbage in...so garbage out. What police/public/complainants need is consistent file assessment; clear definitions. \n",
      "\n",
      "Got questions on the \"gold standard model\" (Philadelphia's oversight) and don't give me lowered \"unfounded rate\"--that's garbage. What's unfounded mean in Philly? Any unintended consequences? Conviction rate up? Stats pls!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "\n",
    "CSV_PATH = BASE_DIR / \"data\" / \"jigsaw_gbv.csv\"\n",
    "\n",
    "print(\"Loading from:\", CSV_PATH)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Harmful comments about women\n",
    "print(\"\\n=== Sample: Harmful comments about women (label=1) ===\")\n",
    "sample_1 = df[df[\"label\"] == 1].sample(5, random_state=42)\n",
    "\n",
    "for _, row in sample_1.iterrows():\n",
    "    print(\"----\")\n",
    "    print(row[\"comment_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52207f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample: Non-harmful comments about women (label=0) ===\n",
      "----\n",
      "AlaskaPI is correct, stalking isn't always sexual in nature. There are people out there that think they are superior, above the law and are out to prove it. I have to shake my head when they suggest the paths the victims have to get something done about it. There is no path! You can file police reports which go into the que, snow removal or police protection, the latter is shut down in this town so there is one option. They go out of their way an send you to an online reporting system which goes into a round file. Our wonderful police department is under orders from Berkie to only respond when the body is cold, anything else gets the shovel....maybe. How many times do we read of someone doing something and they have a record as long as your arm yet they continue till they kill someone. I think there is a very good example the other day, guy kills his wife. Pretty sad when we are paying for both snow and police and get neither. However, we got three bathrooms.\n",
      "----\n",
      "Where were you when the women died in Canada?\n",
      "Where were you when millions of women were subjugated by Muslim men....\n",
      "\n",
      "Phoney\n",
      "----\n",
      "'2 butches'?  hmmmm, think there's a better way to describe these women.\n",
      "----\n",
      "For the benefit of Civil Comments raters, my comment below refers to the hateful comments posted to the letter \"Hillary exactly the type Trump fears\" and the \"Likes\" ...\n",
      "\n",
      "What is it about women that drives \"Gudagook\", \"4:20\", \"LockHer Up\", \"motleycrew\" and \"demiwolf\" so insane?\n",
      "\n",
      "A bit of insecurity about their own virility. perhaps?\n",
      "\n",
      "-- Paul\n",
      "----\n",
      "From a Peaceful Warrior's perspective and dealing with this epidemic of insanity by predation upon women & children has been daunting, with loss of good peaceful warriors to this senseless violence. Brie & Ellis are recent good men doing action to stop insanity of violenc. Please do something to not let their work in saving people from violence go invain. Please step up with peace and kindness to traumatized people, not ridicule & hurt. Finding out after the fact that someone slammed my girlfriend's head of while dancing and saying your kind is not wanted here, is causing speed dialing Buddhism right now & wondering why no one stepped up and stopped the abusive behavior. It takes a village to stop the level of violence against us all. Love to you all. Alaskan white dragon üïâ‚òÆüíöüê≤\n"
     ]
    }
   ],
   "source": [
    "# Non-harmful comments about women\n",
    "print(\"\\n=== Sample: Non-harmful comments about women (label=0) ===\")\n",
    "sample_0 = df[df[\"label\"] == 0].sample(5, random_state=42)\n",
    "\n",
    "for _, row in sample_0.iterrows():\n",
    "    print(\"----\")\n",
    "    print(row[\"comment_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
